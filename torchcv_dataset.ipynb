{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset 方法\n",
    "\n",
    "参数\n",
    "\n",
    "root： 存放的位置\n",
    "\n",
    "train: if True, create from training set, otherwise from testing set\n",
    "\n",
    "transform: a fucntion that takes in an image and transforms it\n",
    "\n",
    "download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [28:00<00:00, 101470.70it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root = \"./dataset\", train = True, download = True)\n",
    "test_set = torchvision.datasets.CIFAR10(root = \"./dataset\", train = True, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7FAFC1AD31F0>, 6)\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "frog\n"
     ]
    }
   ],
   "source": [
    "print(test_set[0])\n",
    "print(test_set.classes)\n",
    "\n",
    "img, target = test_set[0]\n",
    "print(test_set.classes[target])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(\"dataset\", train = False, transform = torchvision.transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = 4, shuffle = True, num_workers = 0, drop_last = False)\n",
    "\n",
    "# batch_size: 会把同一个batch的image和target分别打包\n",
    "# drop last: 不满足一个batch的数据是否扔掉\n",
    "\n",
    "## 测试集\n",
    "img, target = test_data[0]\n",
    "print(img.shape)\n",
    "print(target)\n",
    "\n",
    "writer = SummaryWriter(\"dataloader\")\n",
    "for epoch in range(2):\n",
    "    step = 0\n",
    "    for data in test_loader:\n",
    "        imgs, targets = data\n",
    "        # print(imgs.shape)\n",
    "        # print(targets)\n",
    "        writer.add_images(\"Epoch : {}\".format(epoch), imgs, step)\n",
    "        step += 1\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPbasic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "882c1afb4c9a40325de8f81978e52d317fad24a18050be2528b8982770e49e29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
